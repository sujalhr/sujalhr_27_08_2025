{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e89a0dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import uuid\n",
    "import pytz\n",
    "from datetime import datetime, timedelta, time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7459f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded:\n",
      "Status records: 1849837\n",
      "Business hours records: 35457\n",
      "Timezone records: 4559\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>status</th>\n",
       "      <th>timestamp_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b5d0a65d-6d54-47aa-95e9-9312f0353326</td>\n",
       "      <td>active</td>\n",
       "      <td>2024-10-03 23:33:20.412748 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a792089b-e23d-435f-bc18-113b7cc95e11</td>\n",
       "      <td>active</td>\n",
       "      <td>2024-10-03 23:33:36.781143 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7a242d0e-309c-4915-9755-e9019d69108d</td>\n",
       "      <td>active</td>\n",
       "      <td>2024-10-03 23:33:37.536328 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ca793240-b974-4551-ba0b-649d1a52956c</td>\n",
       "      <td>active</td>\n",
       "      <td>2024-10-03 23:33:56.752347 UTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3a2313be-27d9-429f-9906-ccd142d9906c</td>\n",
       "      <td>active</td>\n",
       "      <td>2024-10-03 23:34:04.138852 UTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               store_id  status  \\\n",
       "0  b5d0a65d-6d54-47aa-95e9-9312f0353326  active   \n",
       "1  a792089b-e23d-435f-bc18-113b7cc95e11  active   \n",
       "2  7a242d0e-309c-4915-9755-e9019d69108d  active   \n",
       "3  ca793240-b974-4551-ba0b-649d1a52956c  active   \n",
       "4  3a2313be-27d9-429f-9906-ccd142d9906c  active   \n",
       "\n",
       "                    timestamp_utc  \n",
       "0  2024-10-03 23:33:20.412748 UTC  \n",
       "1  2024-10-03 23:33:36.781143 UTC  \n",
       "2  2024-10-03 23:33:37.536328 UTC  \n",
       "3  2024-10-03 23:33:56.752347 UTC  \n",
       "4  2024-10-03 23:34:04.138852 UTC  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>dayOfWeek</th>\n",
       "      <th>start_time_local</th>\n",
       "      <th>end_time_local</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d84a4552-3668-4075-ad1d-16840294f818</td>\n",
       "      <td>1</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d84a4552-3668-4075-ad1d-16840294f818</td>\n",
       "      <td>3</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d84a4552-3668-4075-ad1d-16840294f818</td>\n",
       "      <td>4</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d84a4552-3668-4075-ad1d-16840294f818</td>\n",
       "      <td>0</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d84a4552-3668-4075-ad1d-16840294f818</td>\n",
       "      <td>5</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>00:01:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               store_id  dayOfWeek start_time_local  \\\n",
       "0  d84a4552-3668-4075-ad1d-16840294f818          1         00:00:00   \n",
       "1  d84a4552-3668-4075-ad1d-16840294f818          3         00:00:00   \n",
       "2  d84a4552-3668-4075-ad1d-16840294f818          4         00:00:00   \n",
       "3  d84a4552-3668-4075-ad1d-16840294f818          0         00:00:00   \n",
       "4  d84a4552-3668-4075-ad1d-16840294f818          5         00:00:00   \n",
       "\n",
       "  end_time_local  \n",
       "0       00:01:00  \n",
       "1       00:01:00  \n",
       "2       00:01:00  \n",
       "3       00:01:00  \n",
       "4       00:01:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>timezone_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f6e4d870-a273-49cf-be4d-1bf529e26ff3</td>\n",
       "      <td>America/Boise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7fa112c6-fd3a-4ff6-aadb-4b55f2e74048</td>\n",
       "      <td>America/Boise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273c2570-da54-4526-ab33-175e4d7a1609</td>\n",
       "      <td>America/Boise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bad3c0e6-ad67-40b4-aca8-ce1046b25d68</td>\n",
       "      <td>America/Boise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0df89218-fde7-4fc6-83da-1c2fc7b480a0</td>\n",
       "      <td>America/Boise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               store_id   timezone_str\n",
       "0  f6e4d870-a273-49cf-be4d-1bf529e26ff3  America/Boise\n",
       "1  7fa112c6-fd3a-4ff6-aadb-4b55f2e74048  America/Boise\n",
       "2  273c2570-da54-4526-ab33-175e4d7a1609  America/Boise\n",
       "3  bad3c0e6-ad67-40b4-aca8-ce1046b25d68  America/Boise\n",
       "4  0df89218-fde7-4fc6-83da-1c2fc7b480a0  America/Boise"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load data\n",
    "df_status = pd.read_csv('store_status.csv')\n",
    "df_hours = pd.read_csv('menu_hours.csv')\n",
    "df_timezones = pd.read_csv('timezones.csv')\n",
    "\n",
    "print(\"Data loaded:\")\n",
    "print(f\"Status records: {len(df_status)}\")\n",
    "print(f\"Business hours records: {len(df_hours)}\")\n",
    "print(f\"Timezone records: {len(df_timezones)}\")\n",
    "\n",
    "display(df_status.head())\n",
    "display(df_hours.head())\n",
    "display(df_timezones.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e3f2817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4559"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#seting up database\n",
    "con = sqlite3.connect(\"store_monitoring.db\")\n",
    "df_status.to_sql('store_status', con, if_exists='replace', index=False)\n",
    "df_hours.to_sql('menu_hours', con, if_exists='replace', index=False)\n",
    "df_timezones.to_sql('timezones', con, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe9fc302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "\n",
    "def get_store_timezone(store_id, tz_df):\n",
    "    try:\n",
    "        tz_str = tz_df[tz_df['store_id'] == store_id]['timezone_str'].iloc[0]\n",
    "        return pytz.timezone(tz_str)\n",
    "    except (IndexError, KeyError):\n",
    "        return pytz.timezone('America/Chicago')\n",
    "\n",
    "def get_store_hours(store_id, day_of_week, hours_df):\n",
    "    store_hours = hours_df[\n",
    "        (hours_df['store_id'] == store_id) & \n",
    "        (hours_df['dayOfWeek'] == day_of_week)\n",
    "    ]\n",
    "    \n",
    "    if len(store_hours) == 0:\n",
    "        return [(time(0, 0, 0), time(23, 59, 59))]\n",
    "    \n",
    "    hours_list = []\n",
    "    for _, row in store_hours.iterrows():\n",
    "        start = datetime.strptime(row['start_time_local'], \"%H:%M:%S\").time()\n",
    "        end = datetime.strptime(row['end_time_local'], \"%H:%M:%S\").time()\n",
    "        hours_list.append((start, end))\n",
    "    \n",
    "    return hours_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bad6bb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolation logic\n",
    "\n",
    "def calculate_uptime_downtime(store_id, window_start, window_end, hours_df, tz_df, status_df):\n",
    "    #ensure timezone-naive timestamps\n",
    "    if hasattr(window_start, 'tz'):\n",
    "        window_start = window_start.tz_localize(None) if window_start.tz is None else window_start.tz_convert('UTC').tz_localize(None)\n",
    "    if hasattr(window_end, 'tz'):\n",
    "        window_end = window_end.tz_localize(None) if window_end.tz is None else window_end.tz_convert('UTC').tz_localize(None)\n",
    "    \n",
    "    store_tz = get_store_timezone(store_id, tz_df)\n",
    "    \n",
    "    #relevant status data\n",
    "    store_data = status_df[status_df['store_id'] == store_id].copy()\n",
    "    store_data['timestamp_utc'] = pd.to_datetime(store_data['timestamp_utc']).dt.tz_localize(None)\n",
    "    \n",
    "    relevant_data = store_data[\n",
    "        (store_data['timestamp_utc'] >= window_start) & \n",
    "        (store_data['timestamp_utc'] <= window_end)\n",
    "    ].sort_values('timestamp_utc')\n",
    "    \n",
    "    if len(relevant_data) == 0:\n",
    "        return 0, 0\n",
    "    \n",
    "    total_uptime_minutes = 0\n",
    "    total_downtime_minutes = 0\n",
    "    \n",
    "    #process each day in the window\n",
    "    current_day = window_start.date()\n",
    "    end_day = window_end.date()\n",
    "    \n",
    "    while current_day <= end_day:\n",
    "        day_start_utc = datetime.combine(current_day, time.min)\n",
    "        day_start_local = pytz.utc.localize(day_start_utc).astimezone(store_tz)\n",
    "        day_of_week = day_start_local.weekday()\n",
    "        \n",
    "        business_intervals = get_store_hours(store_id, day_of_week, hours_df)\n",
    "        \n",
    "        for start_time, end_time in business_intervals:\n",
    "            interval_start_local = datetime.combine(current_day, start_time)\n",
    "            interval_end_local = datetime.combine(current_day, end_time)\n",
    "            \n",
    "            if interval_end_local <= interval_start_local:\n",
    "                interval_end_local += timedelta(days=1)\n",
    "            \n",
    "            try:\n",
    "                interval_start_utc = store_tz.localize(interval_start_local).astimezone(pytz.utc).replace(tzinfo=None)\n",
    "                interval_end_utc = store_tz.localize(interval_end_local).astimezone(pytz.utc).replace(tzinfo=None)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            analysis_start = max(interval_start_utc, window_start)\n",
    "            analysis_end = min(interval_end_utc, window_end)\n",
    "            \n",
    "            if analysis_start >= analysis_end:\n",
    "                continue\n",
    "            \n",
    "            interval_observations = relevant_data[\n",
    "                (relevant_data['timestamp_utc'] >= analysis_start) &\n",
    "                (relevant_data['timestamp_utc'] <= analysis_end)\n",
    "            ]\n",
    "            \n",
    "            #finding previous status for interpolation\n",
    "            previous_status = 'active'\n",
    "            before_interval = relevant_data[relevant_data['timestamp_utc'] <= analysis_start]\n",
    "            if len(before_interval) > 0:\n",
    "                previous_status = before_interval.iloc[-1]['status']\n",
    "            \n",
    "            #build timeline\n",
    "            timeline = [(analysis_start, previous_status)]\n",
    "            for _, obs in interval_observations.iterrows():\n",
    "                timeline.append((obs['timestamp_utc'], obs['status']))\n",
    "            timeline.append((analysis_end, None))\n",
    "            \n",
    "            #calculating durations\n",
    "            for i in range(len(timeline) - 1):\n",
    "                period_start, status = timeline[i]\n",
    "                period_end, _ = timeline[i + 1]\n",
    "                \n",
    "                duration_minutes = (period_end - period_start).total_seconds() / 60\n",
    "                \n",
    "                if status == 'active':\n",
    "                    total_uptime_minutes += duration_minutes\n",
    "                else:\n",
    "                    total_downtime_minutes += duration_minutes\n",
    "        \n",
    "        current_day += timedelta(days=1)\n",
    "    \n",
    "    return total_uptime_minutes, total_downtime_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a99c4956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store b5d0a65d-6d54-47aa-95e9-9312f0353326 - Last hour: 60.0min up, 0.0min down\n",
      "Store a792089b-e23d-435f-bc18-113b7cc95e11 - Last hour: 60.0min up, 0.0min down\n",
      "Store 7a242d0e-309c-4915-9755-e9019d69108d - Last hour: 60.0min up, 0.0min down\n"
     ]
    }
   ],
   "source": [
    "#test samples logic\n",
    "def test_sample_stores():\n",
    "    df_status['timestamp_utc'] = pd.to_datetime(df_status['timestamp_utc'])\n",
    "    report_time = df_status['timestamp_utc'].max()\n",
    "    if hasattr(report_time, 'tz_localize'):\n",
    "        report_time = report_time.tz_localize(None)\n",
    "    \n",
    "    test_stores = df_status['store_id'].unique()[:3]\n",
    "    \n",
    "    for store_id in test_stores:\n",
    "        hour_start = report_time - pd.Timedelta(hours=1)\n",
    "        uptime_min, downtime_min = calculate_uptime_downtime(\n",
    "            store_id, hour_start, report_time, df_hours, df_timezones, df_status\n",
    "        )\n",
    "        print(f\"Store {store_id} - Last hour: {uptime_min:.1f}min up, {downtime_min:.1f}min down\")\n",
    "\n",
    "test_sample_stores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5132eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate report \n",
    "def generate_complete_report():\n",
    "    all_stores = df_status['store_id'].unique()\n",
    "    current_time = df_status['timestamp_utc'].max()\n",
    "    if hasattr(current_time, 'tz_localize'):\n",
    "        current_time = current_time.tz_localize(None)\n",
    "    \n",
    "    one_hour_ago = current_time - pd.Timedelta(hours=1)\n",
    "    one_day_ago = current_time - pd.Timedelta(days=1)\n",
    "    one_week_ago = current_time - pd.Timedelta(days=7)\n",
    "    \n",
    "    report_data = []\n",
    "    \n",
    "    for i, store_id in enumerate(all_stores):\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processing {i}/{len(all_stores)}\")\n",
    "        \n",
    "        try:\n",
    "            uptime_hour, downtime_hour = calculate_uptime_downtime(\n",
    "                store_id, one_hour_ago, current_time, df_hours, df_timezones, df_status\n",
    "            )\n",
    "            \n",
    "            uptime_day, downtime_day = calculate_uptime_downtime(\n",
    "                store_id, one_day_ago, current_time, df_hours, df_timezones, df_status\n",
    "            )\n",
    "            \n",
    "            uptime_week, downtime_week = calculate_uptime_downtime(\n",
    "                store_id, one_week_ago, current_time, df_hours, df_timezones, df_status\n",
    "            )\n",
    "            \n",
    "            report_row = {\n",
    "                'store_id': store_id,\n",
    "                'uptime_last_hour(in minutes)': round(uptime_hour, 2),\n",
    "                'uptime_last_day(in hours)': round(uptime_day / 60, 2),\n",
    "                'uptime_last_week(in hours)': round(uptime_week / 60, 2),\n",
    "                'downtime_last_hour(in minutes)': round(downtime_hour, 2),\n",
    "                'downtime_last_day(in hours)': round(downtime_day / 60, 2),\n",
    "                'downtime_last_week(in hours)': round(downtime_week / 60, 2)\n",
    "            }\n",
    "            \n",
    "            report_data.append(report_row)\n",
    "            \n",
    "        except Exception as e:\n",
    "            report_row = {\n",
    "                'store_id': store_id,\n",
    "                'uptime_last_hour(in minutes)': 0,\n",
    "                'uptime_last_day(in hours)': 0,\n",
    "                'uptime_last_week(in hours)': 0,\n",
    "                'downtime_last_hour(in minutes)': 0,\n",
    "                'downtime_last_day(in hours)': 0,\n",
    "                'downtime_last_week(in hours)': 0\n",
    "            }\n",
    "            report_data.append(report_row)\n",
    "    \n",
    "    report_df = pd.DataFrame(report_data)\n",
    "    return report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37615e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#API integration \n",
    "report_storage = {}\n",
    "\n",
    "def trigger_report():\n",
    "    report_id = str(uuid.uuid4())\n",
    "    print(f\"Report ID: {report_id}\")\n",
    "    \n",
    "    report_storage[report_id] = {'status': 'Running'}\n",
    "    \n",
    "    try:\n",
    "        report_df = generate_complete_report()\n",
    "        csv_filename = f\"report_{report_id}.csv\"\n",
    "        report_df.to_csv(csv_filename, index=False)\n",
    "        \n",
    "        report_storage[report_id] = {\n",
    "            'status': 'Complete',\n",
    "            'data': report_df,\n",
    "            'filename': csv_filename\n",
    "        }\n",
    "        \n",
    "        print(f\"Report completed: {csv_filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        report_storage[report_id] = {'status': 'Failed', 'error': str(e)}\n",
    "    \n",
    "    return report_id\n",
    "\n",
    "def get_report(report_id):\n",
    "    if report_id not in report_storage:\n",
    "        return \"Invalid report_id\"\n",
    "    \n",
    "    report_info = report_storage[report_id]\n",
    "    status = report_info['status']\n",
    "    \n",
    "    if status == 'Running':\n",
    "        return \"Running\"\n",
    "    elif status == 'Complete':\n",
    "        return \"Complete\", report_info['data']\n",
    "    elif status == 'Failed':\n",
    "        return f\"Failed: {report_info.get('error', 'Unknown error')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a943e9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report ID: 3c789b8a-bf0c-4580-8e95-63f2b41f89c2\n",
      "Processing 0/3678\n",
      "Processing 100/3678\n",
      "Processing 200/3678\n",
      "Processing 300/3678\n",
      "Processing 400/3678\n",
      "Processing 500/3678\n",
      "Processing 600/3678\n",
      "Processing 700/3678\n",
      "Processing 800/3678\n",
      "Processing 900/3678\n",
      "Processing 1000/3678\n",
      "Processing 1100/3678\n",
      "Processing 1200/3678\n",
      "Processing 1300/3678\n",
      "Processing 1400/3678\n",
      "Processing 1500/3678\n",
      "Processing 1600/3678\n",
      "Processing 1700/3678\n",
      "Processing 1800/3678\n",
      "Processing 1900/3678\n",
      "Processing 2000/3678\n",
      "Processing 2100/3678\n",
      "Processing 2200/3678\n",
      "Processing 2300/3678\n",
      "Processing 2400/3678\n",
      "Processing 2500/3678\n",
      "Processing 2600/3678\n",
      "Processing 2700/3678\n",
      "Processing 2800/3678\n",
      "Processing 2900/3678\n",
      "Processing 3000/3678\n",
      "Processing 3100/3678\n",
      "Processing 3200/3678\n",
      "Processing 3300/3678\n",
      "Processing 3400/3678\n",
      "Processing 3500/3678\n",
      "Processing 3600/3678\n",
      "Report completed: report_3c789b8a-bf0c-4580-8e95-63f2b41f89c2.csv\n",
      "\n",
      "Report Status: Complete\n",
      "Total stores processed: 3678\n",
      "\n",
      "Sample results:\n",
      "                               store_id  uptime_last_hour(in minutes)  \\\n",
      "0  b5d0a65d-6d54-47aa-95e9-9312f0353326                          60.0   \n",
      "1  a792089b-e23d-435f-bc18-113b7cc95e11                          60.0   \n",
      "2  7a242d0e-309c-4915-9755-e9019d69108d                          60.0   \n",
      "3  ca793240-b974-4551-ba0b-649d1a52956c                          60.0   \n",
      "4  3a2313be-27d9-429f-9906-ccd142d9906c                          60.0   \n",
      "\n",
      "   uptime_last_day(in hours)  uptime_last_week(in hours)  \\\n",
      "0                      13.44                       89.06   \n",
      "1                      14.03                       97.91   \n",
      "2                      17.05                      119.25   \n",
      "3                       8.98                       60.76   \n",
      "4                      13.43                       93.90   \n",
      "\n",
      "   downtime_last_hour(in minutes)  downtime_last_day(in hours)  \\\n",
      "0                             0.0                         0.54   \n",
      "1                             0.0                         2.97   \n",
      "2                             0.0                         0.45   \n",
      "3                             0.0                         2.52   \n",
      "4                             0.0                         0.05   \n",
      "\n",
      "   downtime_last_week(in hours)  \n",
      "0                          3.91  \n",
      "1                         21.09  \n",
      "2                          3.25  \n",
      "3                         14.74  \n",
      "4                          0.49  \n",
      "\n",
      "Schema verification: True\n"
     ]
    }
   ],
   "source": [
    "#execution of the flow \n",
    "\n",
    "report_id = trigger_report()\n",
    "result = get_report(report_id)\n",
    "\n",
    "if isinstance(result, tuple) and result[0] == \"Complete\":\n",
    "    status, report_df = result\n",
    "    print(f\"\\nReport Status: {status}\")\n",
    "    print(f\"Total stores processed: {len(report_df)}\")\n",
    "    print(\"\\nSample results:\")\n",
    "    print(report_df.head())\n",
    "    \n",
    "    # verify schema\n",
    "    expected_columns = [\n",
    "        'store_id',\n",
    "        'uptime_last_hour(in minutes)',\n",
    "        'uptime_last_day(in hours)', \n",
    "        'uptime_last_week(in hours)',\n",
    "        'downtime_last_hour(in minutes)',\n",
    "        'downtime_last_day(in hours)',\n",
    "        'downtime_last_week(in hours)'\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nSchema verification: {report_df.columns.tolist() == expected_columns}\")\n",
    "else:\n",
    "    print(f\"Result: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
